# Web Scraping - Gu√≠a Completa

> Sistema config-driven para scrapear eventos de sitios web sin APIs p√∫blicas

---

## üìã Tabla de Contenidos

- [Overview](#overview)
- [Arquitectura](#arquitectura)
- [Quick Start](#quick-start)
- [Agregar un Nuevo Sitio](#agregar-un-nuevo-sitio)
- [Configuraci√≥n Avanzada](#configuraci√≥n-avanzada)
- [Transformaciones](#transformaciones)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)
- [Buenas Pr√°cticas](#buenas-pr√°cticas)

---

## Overview

El sistema de web scraping permite extraer eventos de sitios web HTML usando **configuraciones declarativas**. No requiere escribir c√≥digo nuevo para cada sitio, solo definir selectores CSS y transformaciones.

### Caracter√≠sticas

‚úÖ **Config-driven** - Define selectores CSS en archivos de configuraci√≥n
‚úÖ **Rate limiting** - Respeta l√≠mites de requests por segundo
‚úÖ **Retry autom√°tico** - Exponential backoff (1s, 2s, 4s)
‚úÖ **Paginaci√≥n** - Soporte para m√∫ltiples p√°ginas
‚úÖ **Transformaciones** - Parseo de fechas en espa√±ol, precios, sanitizaci√≥n HTML
‚úÖ **Error handling graceful** - Contin√∫a scraping aunque eventos individuales fallen
‚úÖ **Integraci√≥n con Orchestrator** - Compatible con DataSourceOrchestrator
‚úÖ **Tests comprehensivos** - Tests unitarios con fixtures HTML reales

### Sitios Configurados

| Sitio | Estado | Config |
|-------|--------|--------|
| LivePass.com.ar | üü° Template (requiere actualizar selectores) | `src/config/scrapers/livepass.config.ts` |
| _Agregar m√°s aqu√≠_ | - | - |

---

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   DataSourceOrchestrator                     ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Ticketmaster ‚îÇ  ‚îÇ   LivePass   ‚îÇ  ‚îÇ  Alternativa ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   (API)      ‚îÇ  ‚îÇ  (Scraper)   ‚îÇ  ‚îÇ   (Scraper)  ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                  ‚îÇ             ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                             ‚îÇ                                ‚îÇ
‚îÇ                             ‚ñº                                ‚îÇ
‚îÇ                      EventService                            ‚îÇ
‚îÇ                  (Validaci√≥n + Dedup)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes

1. **GenericWebScraper** (`src/features/events/data/sources/web/GenericWebScraper.ts`)
   - Motor principal que ejecuta el scraping
   - Usa Cheerio para parsear HTML
   - Aplica transformaciones configuradas
   - Maneja paginaci√≥n, retry, rate limiting

2. **WebScraperFactory** (`src/features/events/data/sources/web/WebScraperFactory.ts`)
   - Crea scrapers por nombre
   - Registry de configuraciones
   - Permite crear m√∫ltiples scrapers a la vez

3. **ScraperConfig** (`src/features/events/data/sources/web/types/ScraperConfig.ts`)
   - Tipos TypeScript para configuraciones
   - Define estructura de selectores, paginaci√≥n, error handling

4. **Transform Utils** (`src/features/events/data/sources/web/utils/transforms.ts`)
   - Funciones de transformaci√≥n reutilizables
   - `parseSpanishDate`, `extractPrice`, `sanitizeHtml`, etc.

---

## Quick Start

### 1. Usar un Scraper Existente

```typescript
import { WebScraperFactory } from '@/features/events/data/sources/web/WebScraperFactory';

// Crear scraper de LivePass
const livepassScraper = await WebScraperFactory.create('livepass');

// Ejecutar scraping
const events = await livepassScraper.fetch();

console.log(`Scrapeados ${events.length} eventos`);
```

### 2. Integrar con Orchestrator

```typescript
import { DataSourceOrchestrator } from '@/features/events/data/orchestrator/DataSourceOrchestrator';
import { WebScraperFactory } from '@/features/events/data/sources/web/WebScraperFactory';
import { TicketmasterSource } from '@/features/events/data/sources/ticketmaster/TicketmasterSource';

// Crear orchestrator
const repository = new PrismaEventRepository();
const orchestrator = new DataSourceOrchestrator(repository);

// Registrar fuentes (API + Web Scrapers)
orchestrator.registerSource(new TicketmasterSource());
orchestrator.registerSource(await WebScraperFactory.create('livepass'));

// Ejecutar TODO en paralelo
const result = await orchestrator.fetchAll();

console.log(`Total eventos: ${result.totalEvents}`);
console.log(`Procesados: ${result.totalProcessed}`);
console.log(`Duplicados: ${result.totalDuplicates}`);
```

### 3. Crear M√∫ltiples Scrapers

```typescript
// Crear todos los scrapers disponibles
const allScrapers = await WebScraperFactory.createAll();

// O espec√≠ficos
const scrapers = await WebScraperFactory.createMany(['livepass', 'alternativa']);

// Registrar todos
scrapers.forEach(scraper => orchestrator.registerSource(scraper));
```

---

## Agregar un Nuevo Sitio

### Paso 1: Inspeccionar HTML

1. Abrir el sitio en navegador (ej: `https://example.com/eventos`)
2. F12 ‚Üí Tab "Elements" o "Inspector"
3. Encontrar el HTML de los eventos

**Ejemplo de HTML t√≠pico:**

```html
<div class="events-container">
  <div class="event-card">
    <img src="/images/evento1.jpg" class="event-img" />
    <h3 class="event-title">Metallica en vivo</h3>
    <p class="event-date">Viernes 15 de marzo, 21:00hs</p>
    <p class="event-venue">Caf√© Berl√≠n</p>
    <p class="event-location">Palermo, Buenos Aires</p>
    <span class="event-price">$5.000</span>
    <a href="/eventos/metallica-123" class="event-link">Ver m√°s</a>
  </div>
  <!-- m√°s eventos... -->
</div>
```

### Paso 2: Identificar Selectores

| Campo | Selector CSS | Notas |
|-------|--------------|-------|
| Contenedor | `.events-container` | Opcional, contiene todos los eventos |
| Item (cada evento) | `.event-card` | **Requerido**, elemento que se repite |
| T√≠tulo | `.event-title` | **Requerido** |
| Fecha | `.event-date` | **Requerido** |
| Venue | `.event-venue` | **Requerido** |
| Ciudad | `.event-location` | Opcional |
| Precio | `.event-price` | Opcional |
| Imagen | `.event-img@src` | Atributo `src` con `@` |
| Link | `.event-link@href` | Atributo `href` con `@` |

### Paso 3: Crear Configuraci√≥n

Crear archivo `src/config/scrapers/mi-sitio.config.ts`:

```typescript
import { ScraperConfig } from '@/features/events/data/sources/web/types/ScraperConfig';

export const miSitioConfig: ScraperConfig = {
  name: 'mi-sitio',
  type: 'web',
  baseUrl: 'https://example.com',

  listing: {
    url: '/eventos',
    containerSelector: '.events-container', // Opcional
    itemSelector: '.event-card', // Requerido

    pagination: {
      type: 'url',
      pattern: '/eventos?page={page}', // {page} ser√° reemplazado por 1, 2, 3...
      maxPages: 5,
      delayBetweenPages: 1500, // 1.5 segundos entre p√°ginas
    },
  },

  selectors: {
    title: '.event-title',
    date: '.event-date',
    venue: '.event-venue',
    city: '.event-location',
    price: '.event-price',
    image: '.event-img@src', // @ indica atributo
    link: '.event-link@href',
    description: '.event-description',
  },

  transforms: {
    date: 'parseSpanishDate', // Parsear "15 de marzo de 2025"
    price: 'extractPrice', // Extraer n√∫mero de "$5.000"
    description: 'sanitizeHtml', // Limpiar HTML peligroso
    image: 'toAbsoluteUrl', // /images/foo.jpg ‚Üí https://example.com/images/foo.jpg
    link: 'toAbsoluteUrl',
  },

  rateLimit: {
    requestsPerSecond: 1, // Conservador
    timeout: 15000,
  },

  errorHandling: {
    skipFailedEvents: true, // Continuar si un evento falla
    skipFailedPages: false, // Fallar si una p√°gina completa falla
    retry: {
      maxRetries: 3,
      initialDelay: 1000,
      backoffMultiplier: 2, // 1s, 2s, 4s
    },
  },

  userAgent: 'EnVivoBot/1.0 (+https://envivo.ar/bot)',

  headers: {
    Accept: 'text/html,application/xhtml+xml',
    'Accept-Language': 'es-AR,es;q=0.9',
  },
};
```

### Paso 4: Registrar en Factory

Editar `src/features/events/data/sources/web/WebScraperFactory.ts`:

```typescript
const SCRAPER_CONFIGS: Record<string, () => Promise<ScraperConfig>> = {
  livepass: async () => {
    const { livepassConfig } = await import('@/config/scrapers/livepass.config');
    return livepassConfig;
  },
  // ‚úÖ AGREGAR AQU√ç
  'mi-sitio': async () => {
    const { miSitioConfig } = await import('@/config/scrapers/mi-sitio.config');
    return miSitioConfig;
  },
};
```

### Paso 5: Usar el Scraper

```typescript
const miScraper = await WebScraperFactory.create('mi-sitio');
const events = await miScraper.fetch();
```

---

## Configuraci√≥n Avanzada

### Paginaci√≥n

#### Opci√≥n 1: URL Pattern

```typescript
pagination: {
  type: 'url',
  pattern: '/eventos/page/{page}', // /eventos/page/1, /eventos/page/2...
  maxPages: 10,
  delayBetweenPages: 2000, // 2 segundos
}
```

#### Opci√≥n 2: Query Parameter (default)

```typescript
pagination: {
  type: 'url',
  maxPages: 5,
  // Generar√°: /eventos?page=1, /eventos?page=2...
}
```

#### Opci√≥n 3: Sin Paginaci√≥n

```typescript
pagination: {
  type: 'none',
}
// O simplemente omitir el campo
```

### Selectores con Atributos

Para extraer **atributos HTML** (src, href, data-*, etc.) usar sintaxis `@`:

```typescript
selectors: {
  image: '.event-img@src', // <img class="event-img" src="/foo.jpg">
  link: 'a.event-link@href', // <a class="event-link" href="/evento/123">
  videoId: '.video@data-id', // <div class="video" data-id="abc123">
}
```

### Rate Limiting

```typescript
rateLimit: {
  requestsPerSecond: 2, // M√°ximo 2 requests por segundo
  timeout: 20000, // 20 segundos timeout por request
}
```

**Recomendaciones:**
- Sitios peque√±os: 1-2 req/s
- Sitios grandes (Ticketmaster-like): 5 req/s
- **NUNCA** m√°s de 10 req/s

### Error Handling

```typescript
errorHandling: {
  skipFailedEvents: true, // ‚úÖ Recomendado: continuar si evento falla
  skipFailedPages: false, // ‚ùå Fallar si p√°gina completa falla
  retry: {
    maxRetries: 3, // Intentar 3 veces
    initialDelay: 1000, // Primer retry despu√©s de 1s
    backoffMultiplier: 2, // 1s, 2s, 4s
  },
  timeout: 15000, // 15 segundos
}
```

---

## Transformaciones

### Funciones Disponibles

| Funci√≥n | Descripci√≥n | Ejemplo Input | Output |
|---------|-------------|---------------|--------|
| `parseSpanishDate` | Parsea fechas en espa√±ol | "15 de marzo de 2025" | `Date` object |
| `extractPrice` | Extrae precio num√©rico | "$5.000", "Gratis" | `5000`, `0` |
| `sanitizeHtml` | Limpia HTML peligroso | `<script>alert()</script><p>Ok</p>` | `<p>Ok</p>` |
| `cleanWhitespace` | Normaliza espacios | `"  text   with    spaces  "` | `"text with spaces"` |
| `toAbsoluteUrl` | Convierte URL relativa a absoluta | `/images/foo.jpg` | `https://example.com/images/foo.jpg` |

### parseSpanishDate - Formatos Soportados

```typescript
parseSpanishDate("15 de marzo de 2025") // ‚úÖ Fecha completa
parseSpanishDate("15 mar 2025") // ‚úÖ Mes abreviado
parseSpanishDate("15/03/2025") // ‚úÖ Num√©rico con /
parseSpanishDate("15-03-2025") // ‚úÖ Num√©rico con -
parseSpanishDate("2025-03-15") // ‚úÖ ISO format
parseSpanishDate("S√°bado 15 de marzo") // ‚úÖ Con d√≠a de semana
```

### extractPrice - Formatos Soportados

```typescript
extractPrice("$5.000") // ‚Üí 5000
extractPrice("$10.500,50") // ‚Üí 10501 (redondeado)
extractPrice("ARS 1500") // ‚Üí 1500
extractPrice("Desde $2000") // ‚Üí 2000
extractPrice("Gratis") // ‚Üí 0
extractPrice("Free") // ‚Üí 0
```

### Crear Transformaci√≥n Custom

Si necesit√°s una transformaci√≥n especial:

1. Agregar funci√≥n en `src/features/events/data/sources/web/utils/transforms.ts`:

```typescript
export function parseCustomDate(dateString: string): Date | undefined {
  // Tu l√≥gica custom
  return new Date(dateString);
}

// Agregar al registry
export const TRANSFORM_FUNCTIONS: Record<string, Function> = {
  // ... existentes
  parseCustomDate: (value: string) => parseCustomDate(value),
};
```

2. Usar en config:

```typescript
transforms: {
  date: 'parseCustomDate',
}
```

---

## Testing

### Ejecutar Tests

```bash
# Todos los tests de web scraping
npm test -- web

# Solo transforms
npm test -- transforms.test.ts

# Solo GenericWebScraper
npm test -- GenericWebScraper.test.ts
```

### Crear Test para Nuevo Sitio

Crear `src/features/events/data/sources/web/fixtures/mi-sitio.html`:

```html
<!DOCTYPE html>
<html>
<body>
  <div class="events-container">
    <div class="event-card">
      <h3 class="event-title">Test Event</h3>
      <p class="event-date">15 de marzo de 2025</p>
      <p class="event-venue">Test Venue</p>
    </div>
  </div>
</body>
</html>
```

Crear test `src/features/events/data/sources/web/scrapers/MiSitioScraper.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { GenericWebScraper } from '../GenericWebScraper';
import { miSitioConfig } from '@/config/scrapers/mi-sitio.config';
import { readFileSync } from 'fs';

const MOCK_HTML = readFileSync('./fixtures/mi-sitio.html', 'utf-8');

describe('MiSitio Scraper', () => {
  it('should extract events correctly', async () => {
    // Mock axios
    vi.mock('axios');

    const scraper = new GenericWebScraper(miSitioConfig);
    const events = await scraper.fetch();

    expect(events).toHaveLength(1);
    expect(events[0].title).toBe('Test Event');
  });
});
```

---

## Troubleshooting

### Error: "Cannot find module 'isomorphic-dompurify'"

**Soluci√≥n:**
```bash
npm install
```

### Error: 403 Forbidden

**Causa**: El sitio bloquea requests automatizados.

**Soluciones:**
1. Cambiar User-Agent:
```typescript
userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
```

2. Agregar headers realistas:
```typescript
headers: {
  'Accept': 'text/html,application/xhtml+xml',
  'Accept-Language': 'es-AR,es;q=0.9',
  'Accept-Encoding': 'gzip, deflate, br',
  'Cache-Control': 'no-cache',
}
```

3. Reducir rate limit:
```typescript
rateLimit: {
  requestsPerSecond: 0.5, // 1 request cada 2 segundos
}
```

### Error: Selector no encuentra elementos

**Debug:**
```typescript
// Agregar logs temporales en GenericWebScraper
console.log('HTML:', html.substring(0, 500)); // Ver HTML recibido
console.log('Items found:', $items.length); // Ver cu√°ntos items se encuentran
```

**Soluciones:**
1. Verificar selector con DevTools:
   - F12 ‚Üí Console
   - `document.querySelectorAll('.event-card')` debe retornar elementos

2. HTML puede ser din√°mico (JS):
   - Si el sitio usa React/Vue, el HTML se genera con JS
   - Cheerio solo ve HTML est√°tico
   - **Soluci√≥n**: Usar Playwright (m√°s lento pero renderiza JS)

### Eventos con campos faltantes

**Debug:** Ver logs en console:
```
[livepass] Skipping event with missing required fields: title=undefined, date=2025-03-15, venue=Caf√© Berl√≠n
```

**Soluci√≥n:** Ajustar selectores CSS

---

## Buenas Pr√°cticas

### ‚úÖ DO

- **Respetar robots.txt** del sitio
- **Rate limiting conservador**: Empezar con 1 req/s
- **User-Agent honesto**: Identificarse como bot
- **Cach√©**: No scrapear mismo contenido repetidamente
- **Logs**: Loggear eventos fallidos con contexto
- **Tests con fixtures**: Usar HTML fixtures, no requests reales
- **Sanitizar HTML**: Siempre usar `sanitizeHtml` en descripciones

### ‚ùå DON'T

- **No hacer m√°s de 10 req/s** (saturar servidor)
- **No scrapear datos privados** (requieren login)
- **No ignorar errores 403/429** (indica que est√°s bloqueado)
- **No hardcodear datos** en scrapers (usar config)
- **No commitear HTML fixtures grandes** (>100 KB)
- **No scrapear si hay API disponible** (siempre preferir API)

### √âtica del Web Scraping

1. **Verificar T√©rminos de Servicio**: Algunos sitios proh√≠ben scraping
2. **Contactar al sitio**: Preguntar si tienen API o permiten scraping
3. **Atribuci√≥n**: Dar cr√©dito al sitio origen
4. **No competir directamente**: No clonar el sitio
5. **Rate limiting**: No afectar performance del sitio

---

## Recursos

### Documentaci√≥n

- [Cheerio](https://cheerio.js.org/) - jQuery-like HTML parsing
- [CSS Selectors Reference](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)
- [DOMPurify](https://github.com/cure53/DOMPurify) - Sanitizaci√≥n HTML

### Tools

- **Chrome DevTools**: F12 ‚Üí Elements ‚Üí Inspeccionar HTML
- **CSS Selector Tester**: `document.querySelectorAll('.selector')` en Console
- **Postman/Insomnia**: Testear headers y responses

### Pr√≥ximos Pasos

1. ‚úÖ Completado: Arquitectura base
2. üîÑ En progreso: Actualizar selectores de LivePass
3. ‚è≥ Pendiente: Integrar en `/api/admin/scraper/sync`
4. ‚è≥ Pendiente: Agregar m√°s sitios (Alternativa Teatral, PassLine)
5. ‚è≥ Pendiente: Implementar Playwright para sitios JS-heavy

---

**√öltima actualizaci√≥n**: 9 de Noviembre de 2025
