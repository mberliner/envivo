# GuÃ­a de Web Scraping - LivePass (CafÃ© BerlÃ­n)

## ğŸš€ Quick Start

### 1. Iniciar el servidor de desarrollo

```bash
npm run dev
```

Espera a que el servidor estÃ© listo en `http://localhost:3000`

### 2. Ejecutar el scraping

**OpciÃ³n A: Con Node.js (Recomendado)**
```bash
node scripts/scrape-livepass.js
```

**OpciÃ³n B: Con Bash + curl**
```bash
./scripts/scrape-livepass.sh
```

**OpciÃ³n C: Manualmente con curl**
```bash
curl -X POST http://localhost:3000/api/admin/scrape \
  -H "Authorization: Bearer YOUR_ADMIN_API_KEY" \
  -H "Content-Type: application/json"
```

---

## ğŸ“Š Ejemplo de Output

```
ğŸš€ Iniciando scraping de LivePass (CafÃ© BerlÃ­n)...

âœ… Scraping completado exitosamente!

ğŸ“Š Resultados:
   â€¢ Total eventos scrapeados: 48
   â€¢ Eventos procesados: 35
   â€¢ Duplicados detectados: 13
   â€¢ Errores: 0
   â€¢ DuraciÃ³n: 2847ms

ğŸ“‹ Detalle por fuente:
   âœ… livepass: 48 eventos (2654ms)
```

---

## ğŸ” Verificar los Datos Scrapeados

### OpciÃ³n 1: En la UI

1. Ve a `http://localhost:3000/events`
2. Filtra por ciudad: **Buenos Aires**
3. DeberÃ­as ver eventos de **CafÃ© BerlÃ­n**

### OpciÃ³n 2: En la base de datos

```bash
# Usando Prisma Studio
npx prisma studio

# O con SQL directo
sqlite3 prisma/dev.db "SELECT title, venue, city, date FROM Event WHERE venue = 'CafÃ© BerlÃ­n' LIMIT 10;"
```

---

## ğŸ› ï¸ Troubleshooting

### Error: "ADMIN_API_KEY no estÃ¡ configurado"

Verifica que `.env.local` tenga:
```env
ADMIN_API_KEY="tu-api-key-aqui"
```

> Ver [docs/ENV_SETUP.md](ENV_SETUP.md) para guÃ­a completa de configuraciÃ³n.

### Error: "No se puede conectar al servidor"

AsegÃºrate de que el servidor estÃ© corriendo:
```bash
npm run dev
```

### Error: "Unauthorized" (401)

Verifica que el `ADMIN_API_KEY` en `.env.local` coincida con el que usas en la request.

### Error: "Failed to scrape livepass"

Posibles causas:
- El sitio LivePass estÃ¡ caÃ­do o cambiÃ³ su estructura
- Problemas de red
- Rate limiting

Revisa los logs del servidor para mÃ¡s detalles.

---

## ğŸ“ QuÃ© hace el scraper

El scraper de LivePass (`livepass.config.ts`):

1. **Extrae** eventos de https://livepass.com.ar/taxons/cafe-berlin
2. **Parsea** informaciÃ³n:
   - TÃ­tulo (limpia " en CafÃ© BerlÃ­n" del final)
   - Fecha (formato "09 NOV" â†’ convierte a Date)
   - Imagen
   - Link al evento
3. **Asigna** valores hardcodeados:
   - Venue: "CafÃ© BerlÃ­n"
   - City: "Buenos Aires"
   - Country: "AR"
   - Category: "Concierto"
4. **Valida** con `EventBusinessRules`
5. **Deduplica** usando fuzzy matching
6. **Guarda** en la base de datos

---

## ğŸ”„ AutomatizaciÃ³n (Futuro)

Para ejecutar el scraping automÃ¡ticamente cada dÃ­a:

### OpciÃ³n 1: Cron Job (Linux/Mac)
```bash
# Editar crontab
crontab -e

# Agregar lÃ­nea (ejecutar a las 2 AM cada dÃ­a)
0 2 * * * cd /path/to/envivo && node scripts/scrape-livepass.js >> logs/scraping.log 2>&1
```

### OpciÃ³n 2: GitHub Actions
Ver `docs/examples/cicd-example.yml` para workflow de scraping automÃ¡tico.

### OpciÃ³n 3: Vercel Cron Jobs
Ver documentaciÃ³n en `docs/PRODUCT.md` (Fase 6: Deployment).

---

## ğŸ“– Referencias

- **ConfiguraciÃ³n del scraper**: `/config/scrapers/livepass.config.ts`
- **Transformaciones custom**: `/src/features/events/data/sources/web/utils/transforms.ts`
  - `parseLivepassDate()`: Parsea "09 NOV" â†’ Date
  - `cleanLivepassTitle()`: Remueve " en CafÃ© BerlÃ­n"
- **Generic Web Scraper**: `/src/features/events/data/sources/web/GenericWebScraper.ts`
- **Orchestrator**: `/src/features/events/data/orchestrator/DataSourceOrchestrator.ts`

---

## ğŸ¯ Siguientes Pasos

1. âœ… **Scraper funcionando** (LivePass - CafÃ© BerlÃ­n)
2. â³ **Agregar mÃ¡s fuentes**:
   - Eventbrite Argentina
   - Passline
   - Otros venues locales
3. â³ **Automatizar** con cron jobs o Vercel Cron
4. â³ **Monitoring** y alertas si scraping falla

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025
