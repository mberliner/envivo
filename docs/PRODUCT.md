# Product Documentation - EnVivo

## Tabla de Contenidos

1. [Features del MVP](#features-del-mvp)
2. [√âpicas](#√©picas)
3. [Definici√≥n de Terminado (General)](#definici√≥n-de-terminado-general)
4. [User Stories](#user-stories)
5. [Roadmap de Implementaci√≥n](#roadmap-de-implementaci√≥n)
6. [M√©tricas de √âxito](#m√©tricas-de-√©xito)
7. [Checklist Pre-Launch](#checklist-pre-launch)

---

## Features del MVP

### ‚úÖ Core Features (Must-Have)

| Feature | Descripci√≥n | Prioridad |
|---------|-------------|-----------|
| **B√∫squeda por texto** | Buscar eventos por t√≠tulo, artista o venue | üî¥ CR√çTICO |
| **Filtros avanzados** | Filtrar por ciudad, fecha, categor√≠a | üî¥ CR√çTICO |
| **Detalle de evento** | Ver informaci√≥n completa del evento | üî¥ CR√çTICO |
| **Scraping autom√°tico** | Actualizaci√≥n diaria de eventos | üî¥ CR√çTICO |
| **Integraci√≥n Ticketmaster** | API de Ticketmaster como fuente principal | üî¥ CR√çTICO |
| **Scrapers locales** | M√≠nimo 2 sitios locales scrapeados | üü° IMPORTANTE |
| **Validaci√≥n de datos** | Reglas de negocio para calidad de datos | üü° IMPORTANTE |
| **Deduplicaci√≥n** | Detectar eventos duplicados autom√°ticamente | üü° IMPORTANTE |

### üö´ NO Incluir en MVP (Post-MVP)

| Feature | Por qu√© NO en MVP | Cu√°ndo Agregar |
|---------|-------------------|----------------|
| Cuentas de usuario | No es necesario para b√∫squeda b√°sica | Fase 2 (Mes 2) |
| Favoritos/guardados | Requiere autenticaci√≥n | Fase 2 |
| Notificaciones | Requiere usuarios + infraestructura | Fase 3 |
| Recomendaciones personalizadas | Requiere ML + historial | Fase 3 |
| Integraci√≥n Spotify | Nice-to-have, no core | Fase 2-3 |
| Compra de entradas directa | Complejidad legal/financiera | Nunca (links externos OK) |

---

## √âpicas

### Epic 1: B√∫squeda de Eventos

**Objetivo**: Los usuarios pueden buscar y filtrar eventos musicales f√°cilmente.

**User Stories**:
- US1.1: B√∫squeda por texto
- US1.2: Filtros avanzados (ciudad, fecha, categor√≠a)
- US1.3: Ordenamiento de resultados

**Criterios de √âxito**:
- B√∫squeda responde en <500ms (p95)
- Filtros se pueden combinar
- Resultados relevantes (FTS5)

---

### Epic 2: Visualizaci√≥n de Eventos

**Objetivo**: Los usuarios pueden ver informaci√≥n detallada de eventos.

**User Stories**:
- US2.1: Ver detalle completo de evento
- US2.2: Ver ubicaci√≥n en mapa (opcional MVP)
- US2.3: Link a compra de entradas

**Criterios de √âxito**:
- Toda la informaci√≥n visible (t√≠tulo, fecha, venue, precio)
- Im√°genes optimizadas (Next.js Image)
- Links externos funcionan

---

### Epic 3: Scraping y Gesti√≥n de Datos

**Objetivo**: El sistema mantiene datos actualizados autom√°ticamente.

**User Stories**:
- US3.0: Poblaci√≥n inicial de base de datos (scraping manual)
- US3.1: Scraping autom√°tico diario
- US3.2: Validaci√≥n de datos
- US3.3: Deduplicaci√≥n de eventos
- US3.4: Configuraci√≥n de preferencias globales (Post-MVP Fase 1.5)
- US3.5: Re-scraping manual con preferencias actualizadas (Post-MVP Fase 1.5)

**Criterios de √âxito**:
- BD se puede poblar desde cero con scraping manual
- Scraping >90% success rate
- No eventos duplicados en BD
- Logs claros de cada ejecuci√≥n
- Eventos rechazados por preferencias quedan registrados con raz√≥n
- Preferencias se pueden configurar v√≠a UI admin (Post-MVP)

**Nota**: Scraping manual (`POST /api/admin/scraper/sync`) es **CR√çTICO** para MVP - permite poblar BD inicial y re-scraping bajo demanda.

---

## Definici√≥n de Terminado (General)

Aplica a todas las historias de usuario del MVP.

- [ ] Tests relevantes pasan (unitarios e integraci√≥n seg√∫n corresponda)
- [ ] Tipado TypeScript sin errores (`npm run type-check`)
- [ ] Linter y formato sin issues (`npm run lint` y Prettier)
- [ ] Manejo de errores y estados de carga implementados
- [ ] Logs m√≠nimos √∫tiles sin datos sensibles
- [ ] UI responsive b√°sica y accesible (navegable con teclado, labels)
- [ ] Performance razonable para el caso (sin bloqueos visibles en UI)
- [ ] Documentaci√≥n t√©cnica m√≠nima en el c√≥digo donde sea necesario

---

## User Stories

### US1.1: B√∫squeda por Texto

**Como** usuario
**Quiero** buscar eventos por t√≠tulo o artista
**Para** encontrar shows que me interesan

**Criterios de Aceptaci√≥n**:
- [ ] Puedo escribir texto en la barra de b√∫squeda
- [ ] Los resultados se filtran al presionar "Buscar" o Enter
- [ ] Se muestran al menos: t√≠tulo, fecha, venue, imagen
- [ ] Si no hay resultados, se muestra mensaje claro
- [ ] La b√∫squeda funciona con acentos o sin ellos (ej: "Metallica" = "Met√°llica")
- [ ] B√∫squeda case-insensitive
- [ ] Si la consulta tiene menos de 2 caracteres, no se ejecuta b√∫squeda y se muestra sugerencia para ampliar el t√©rmino
- [ ] Resultados paginados o con "cargar m√°s" y se muestra el conteo total de resultados

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US1.2: Filtros Avanzados

**Como** usuario
**Quiero** filtrar eventos por ciudad, fecha y categor√≠a
**Para** encontrar eventos espec√≠ficos de mi inter√©s

**Criterios de Aceptaci√≥n**:
- [ ] Puedo seleccionar ciudad de una lista (dropdown)
- [ ] Puedo seleccionar rango de fechas con date picker
- [ ] Puedo filtrar por categor√≠a (Concierto, Festival, Teatro, Stand-up)
- [ ] Los filtros se pueden combinar (ej: Buenos Aires + Conciertos + Pr√≥xima semana)
- [ ] Los filtros se pueden limpiar con un bot√≥n "Limpiar filtros"
- [ ] Filtros persisten en URL (compartibles via link)
 - [ ] Al cambiar filtros, la vista vuelve al inicio de la lista de resultados
 - [ ] Valores inv√°lidos de filtros recibidos por URL se ignoran y se normalizan a valores por defecto

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US2.1: Ver Detalle de Evento

**Como** usuario
**Quiero** ver informaci√≥n completa de un evento
**Para** decidir si quiero asistir

**Criterios de Aceptaci√≥n**:
- [ ] Se muestra imagen del evento (o placeholder si no hay)
- [ ] Se muestra t√≠tulo, fecha, hora, venue
- [ ] Se muestra descripci√≥n completa (si est√° disponible)
- [ ] Se muestra precio (si est√° disponible)
- [ ] Hay bot√≥n "Comprar entradas" que abre link externo en nueva pesta√±a
- [ ] Se muestra mapa con ubicaci√≥n del venue (opcional para MVP)
- [ ] Se muestran artistas participantes (si hay)
 - [ ] Si el evento no existe, se muestra p√°gina 404 con mensaje claro
 - [ ] Las im√°genes muestran skeleton de carga y fallback ante error
 - [ ] Existe un enlace "Volver a resultados" que preserva query y filtros previos

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US3.0: Poblaci√≥n Inicial de Base de Datos

**Como** administrador del sistema
**Quiero** ejecutar scraping manual para poblar la BD por primera vez
**Para** tener datos iniciales antes de que inicie el scraping autom√°tico

**Contexto**: Al iniciar el proyecto, la BD est√° vac√≠a. Este endpoint permite llenarla manualmente.

**Criterios de Aceptaci√≥n**:
- [ ] Endpoint `POST /api/admin/scraper/sync` disponible
- [ ] Requiere autenticaci√≥n con header `x-api-key` (m√≠nimo 32 caracteres)
- [ ] Carga preferencias por defecto si no existen (lazy initialization):
  - allowedCountries: `['AR']`
  - allowedCities: `['Buenos Aires', 'Ciudad de Buenos Aires', 'CABA']`
  - allowedCategories: `['Music', 'Concert', 'Festival']`
  - allowedVenueSizes: `['small', 'medium', 'large']`
- [ ] Ejecuta scraping de todas las fuentes configuradas en paralelo
- [ ] Aplica validaci√≥n de business rules y filtrado por preferencias
- [ ] Deduplica eventos antes de guardar
- [ ] Retorna resumen JSON: total scrapeado, aceptados, rechazados, razones, duraci√≥n
- [ ] Marca `needsRescraping=false` al finalizar exitosamente
- [ ] Rate limiting: m√°ximo 10 requests cada 10 segundos
- [ ] Timeout global: 5 minutos
- [ ] Logs estructurados con Pino (redactando API keys)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

**Ejemplo de uso**:
```bash
curl -X POST http://localhost:3000/api/admin/scraper/sync \
  -H "x-api-key: your-admin-key-min-32-chars"
```

**Respuesta esperada**:
```json
{
  "status": "success",
  "summary": {
    "totalScraped": 500,
    "accepted": 350,
    "rejected": 150,
    "durationMs": 4200
  },
  "rejectionReasons": {
    "COUNTRY_NOT_ALLOWED": 80,
    "INVALID_DATE_PAST": 70
  }
}
```

---

### US3.1: Scraping Autom√°tico Diario

**Como** administrador del sistema
**Quiero** que los datos se actualicen autom√°ticamente cada d√≠a
**Para** tener eventos siempre actualizados sin intervenci√≥n manual

**Criterios de Aceptaci√≥n**:
- [ ] El scraping se ejecuta diariamente a las 2 AM UTC
- [ ] Se scrapean m√≠nimo 3 fuentes (Ticketmaster + 2 locales)
- [ ] Los eventos duplicados no se guardan (fuzzy matching)
- [ ] Los eventos pasados se mantienen en BD (hist√≥rico) pero no se muestran
- [ ] Se env√≠a notificaci√≥n (log visible) si el scraping falla
- [ ] Se pueden ver logs de √∫ltima ejecuci√≥n en `/api/scraper/status`
 - [ ] Si una fuente falla, el estado expone fuente, timestamp y motivo del fallo
 - [ ] Retries con backoff quedan registrados por fuente con contador visible en el estado

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US3.2: Validaci√≥n de Datos

**Como** sistema
**Quiero** validar todos los eventos antes de guardarlos
**Para** asegurar calidad de datos en la aplicaci√≥n

**Criterios de Aceptaci√≥n**:
- [ ] Eventos sin t√≠tulo se rechazan
- [ ] Eventos sin fecha se rechazan
- [ ] Eventos sin venue se rechazan
- [ ] Fechas pasadas >1 d√≠as se rechazan
- [ ] Pa√≠ses fuera de la lista permitida se rechazan
- [ ] T√≠tulos demasiado cortos (<3 caracteres) se rechazan
- [ ] Se loggean eventos rechazados con raz√≥n clara
- [ ] La raz√≥n de rechazo se persiste con un c√≥digo estandarizado (p.ej., MISSING_DATE, OUT_OF_SCOPE_COUNTRY)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE

---

### US3.3: Deduplicaci√≥n de Eventos

**Como** usuario
**Quiero** rechazar eventos duplicados de diferentes fuentes
**Para** no mostrar el mismo evento m√∫ltiples veces

**Criterios de Aceptaci√≥n**:
- [ ] Eventos con t√≠tulos >85% similares se consideran duplicados
- [ ] Eventos en la misma fecha ¬±24h se consideran duplicados
- [ ] Eventos en el mismo venue se consideran duplicados
- [ ] Se prefiere la fuente m√°s confiable (ej: Ticketmaster > scraper local)
- [ ] Se mergean campos si una fuente tiene m√°s informaci√≥n
 - [ ] No hay duplicados visibles en la UI tras el proceso de deduplicaci√≥n

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE

---

### US3.4: Configuraci√≥n de Preferencias Globales (UI Admin)

**Como** administrador del sistema
**Quiero** configurar preferencias globales de scraping
**Para** obtener solo eventos relevantes y optimizar uso de recursos

**Criterios de Aceptaci√≥n**:
- [ ] Puedo acceder a p√°gina `/admin/preferences` con formulario de configuraci√≥n
- [ ] Puedo configurar pa√≠ses permitidos (multi-select con c√≥digos ISO)
- [ ] Puedo configurar ciudades espec√≠ficas (opcional, lista editable)
- [ ] Puedo seleccionar g√©neros musicales de inter√©s (multi-select)
- [ ] Puedo seleccionar g√©neros bloqueados (lista negra opcional)
- [ ] Puedo elegir categor√≠as de eventos permitidas (Concierto, Festival, Teatro, etc.)
- [ ] Puedo filtrar por tama√±o de venue (peque√±o <500, mediano 500-2000, grande >2000)
- [ ] Los umbrales de capacidad de venue son configurables
- [ ] Las preferencias se guardan en base de datos (tabla GlobalPreferences)
- [ ] Cambiar preferencias marca autom√°ticamente necesidad de re-scraping
- [ ] Hay bot√≥n "Guardar" (solo guarda) y "Guardar y Re-scrapear Ahora" (ejecuta scraping inmediato)
- [ ] La p√°gina muestra √∫ltima actualizaci√≥n y conteo de eventos actuales en BD
- [ ] Hay validaci√≥n: al menos 1 pa√≠s debe estar seleccionado
- [ ] Se muestra modal de confirmaci√≥n antes de ejecutar re-scraping
- [ ] Durante re-scraping se muestra progreso o spinner
- [ ] Al completar, se muestra resumen de eventos scrapeados/aceptados/rechazados

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE (Post-MVP Fase 1.5)

---

### US3.5: Re-scraping Manual con Preferencias Actualizadas

**Como** administrador
**Quiero** ejecutar scraping manual despu√©s de cambiar preferencias
**Para** actualizar la BD con los nuevos filtros

**Contexto**: Cuando se actualizan preferencias globales (ej: agregar m√°s pa√≠ses), se marca `needsRescraping=true`. Este flujo aplica los nuevos filtros.

**Criterios de Aceptaci√≥n**:
- [ ] Endpoint `POST /api/admin/scraper/sync?applyNewPreferences=true` disponible
- [ ] Invalida cach√© de preferencias antes de scrapear
- [ ] Lee nuevas preferencias de BD
- [ ] Ejecuta scraping aplicando nuevos filtros
- [ ] Solo guarda eventos que cumplen nuevas preferencias
- [ ] Marca `needsRescraping=false` al finalizar exitosamente
- [ ] Retorna resumen con eventos aceptados/rechazados por las nuevas reglas
- [ ] Si scraping falla, no marca como completado (permite retry)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE (Post-MVP Fase 1.5)

**Nota**: El endpoint base (`POST /api/admin/scraper/sync`) ya existe desde US3.0. Esta US solo agrega el par√°metro `applyNewPreferences`.

---

## Roadmap de Implementaci√≥n

### Fase 1: Setup Inicial (D√≠a 1)

**Objetivo**: Proyecto configurado y funcionando localmente.

**Tareas**:
1. Inicializar Next.js 14 con TypeScript
2. Configurar Prisma + SQLite
3. Setup Tailwind CSS + shadcn/ui
4. Crear estructura de carpetas (Clean Architecture)
5. Configurar ESLint + Prettier
6. Setup Git + GitHub repo
7. Configurar variables de entorno

**Entregable**: `npm run dev` funciona, estructura de carpetas creada.

---

### Fase 2: Capa de Datos (D√≠as 2-3)

**Objetivo**: Sistema de scraping as√≠ncrono funcionando.

**Tareas**:
1. Crear interfaces base (`IDataSource`, `IEventRepository`)
2. Implementar `DataSourceOrchestrator` con async scraping
3. Implementar `TicketmasterSource` (API client)
4. Crear mappers (`TicketmasterMapper`)
5. Implementar `EventRepository` con Prisma
6. Implementar `EventBusinessRules` (validaci√≥n, deduplicaci√≥n)
7. Tests unitarios de orchestrator y business rules

**Entregable**: Scraping funciona, eventos se guardan en SQLite.

---

### Fase 3: B√∫squeda (D√≠a 4)

**Objetivo**: Motor de b√∫squeda funcionando.

**Tareas**:
1. Configurar SQLite FTS5 en Prisma
2. Implementar `SearchService` (b√∫squeda por texto)
3. Implementar filtros (ciudad, fecha, categor√≠a)
4. Tests de b√∫squeda

**Entregable**: API `/api/eventos?q=Metallica&city=Buenos Aires` funciona.

---

### Fase 4: API Routes (D√≠a 5)

**Objetivo**: Endpoints REST funcionando.

**Tareas**:
1. GET `/api/eventos` (b√∫squeda con filtros)
2. GET `/api/eventos/[id]` (detalle)
3. POST `/api/scraper/sync` (trigger scraping manual)
4. GET `/api/scraper/status` (estado de scraping)
5. Validaci√≥n de query params con Zod
6. Rate limiting b√°sico
7. Error handling

**Entregable**: API REST completa y documentada.

---

### Fase 5: UI/UX (D√≠as 6-8)

**Objetivo**: Interfaz de usuario completa.

**Tareas**:
1. P√°gina home con buscador
2. Componente `EventCard` (lista)
3. Componente `EventFilters` (sidebar)
4. P√°gina detalle de evento
5. Componente `SearchBar` con debounce
6. Loading states y error states
7. Responsive design (mobile-first)
8. Optimizaci√≥n de im√°genes (Next.js Image)

**Entregable**: UI completa y funcional.

---

### Fase 6: Automatizaci√≥n (D√≠a 9)

**Objetivo**: Scraping autom√°tico y monitoring.

**Tareas**:
1. GitHub Action para scraping diario (cron)
2. GitHub Action para tests en CI
3. Setup logging con Pino
4. Error handling global
5. Sentry integration (opcional)
6. Vercel deployment config

**Entregable**: Scraping autom√°tico funcionando, logs estructurados.

---

### Fase 7: Testing & Deploy (D√≠a 10)

**Objetivo**: Proyecto testeado y en producci√≥n.

**Tareas**:

1. Tests unitarios de business rules (>80% coverage)
2. Tests E2E con Playwright (flujos cr√≠ticos)
3. Performance testing (b√∫squeda <500ms)
4. Security audit (`npm audit`)
5. Deploy a Vercel
6. Configurar variables de entorno en Vercel
7. Verificar scraping diario funciona

**Entregable**: Proyecto en producci√≥n en Vercel.

---

## M√©tricas de √âxito

### Objetivos del MVP

| M√©trica | Objetivo | C√≥mo Medirlo |
|---------|----------|--------------|
| **Performance** | B√∫squeda <500ms (p95) | Vercel Analytics |
| **Disponibilidad** | >99% uptime | Vercel Monitoring |
| **Datos** | >500 eventos activos | Query a BD: `SELECT COUNT(*) FROM Event WHERE date > NOW()` |
| **Scraping Success Rate** | >90% de fuentes exitosas | Logs del orchestrator |
| **Cobertura de Tests** | >80% dominio, >60% total | Vitest coverage report |
| **Errores en Producci√≥n** | <5 errores/d√≠a | Sentry o Vercel logs |
| **Lighthouse Score** | >90 Performance | Lighthouse CI |

### KPIs de Negocio (Post-MVP)

| KPI | Objetivo (Mes 1) | C√≥mo Medirlo |
|-----|------------------|--------------|
| B√∫squedas/d√≠a | 50+ | Log de requests a `/api/eventos` |
| Eventos mostrados/d√≠a | 200+ | Log de visualizaciones |

---

## Checklist Pre-Launch

### Funcionalidad

- [ ] B√∫squeda por texto funciona correctamente
- [ ] Filtros (ciudad, fecha, categor√≠a) funcionan y se pueden combinar
- [ ] Detalle de evento muestra toda la informaci√≥n
- [ ] Links a compra de entradas se abren en nueva pesta√±a
- [ ] Scraping diario configurado y funcionando
- [ ] No hay eventos duplicados visibles

### Calidad

- [ ] Tests unitarios >80% cobertura (capa de dominio)
- [ ] Tests E2E para flujos cr√≠ticos (b√∫squeda, detalle) pasan
- [ ] No hay errores de TypeScript (`npm run type-check`)
- [ ] Linter pasa sin warnings (`npm run lint`)
- [ ] C√≥digo formateado con Prettier

### Performance

- [ ] Lighthouse score >90 (Performance)
- [ ] B√∫squeda responde en <500ms con 1000+ eventos
- [ ] Im√°genes optimizadas con Next.js Image component
- [ ] Lazy loading de componentes pesados
- [ ] Build de producci√≥n exitoso (`npm run build`)

### Seguridad

**Ver [SECURITY.md](SECURITY.md) para gu√≠a completa de seguridad.**

- [ ] Validaci√≥n Zod en todos los inputs de API
- [ ] Rate limiting implementado en endpoints p√∫blicos
- [ ] Headers de seguridad configurados (CSP, HSTS, X-Frame-Options)
- [ ] No hay secretos hardcoded en c√≥digo
- [ ] `.env` en `.gitignore`
- [ ] `npm audit` sin vulnerabilidades cr√≠ticas o altas
- [ ] Sanitizaci√≥n de datos scrapeados (DOMPurify)

### Deploy

- [ ] Variables de entorno configuradas en Vercel
- [ ] GitHub Actions funcionando (tests + deploy)
- [ ] Dominio configurado (opcional, puede ser subdomain de Vercel)
- [ ] Monitoring activo (Vercel logs + Sentry opcional)
- [ ] Scraping diario ejecut√°ndose correctamente
- [ ] Logs accesibles y legibles

### Documentaci√≥n

- [ ] README.md actualizado con instrucciones
- [ ] Variables de entorno documentadas en `.env.example`
- [ ] Arquitectura documentada en `docs/ARCHITECTURE.md`
- [ ] User stories y roadmap en `docs/PRODUCT.md`

---

## Features Post-MVP (Roadmap Futuro)

### Fase 2 (Mes 2)

- [ ] Autenticaci√≥n con NextAuth.js
- [ ] Favoritos/guardados de eventos
- [ ] Notificaciones de nuevos eventos (email)
- [ ] M√°s scrapers locales (objetivo: 10 fuentes)
- [ ] Migraci√≥n a PostgreSQL (si >10K eventos)

### Fase 3 (Mes 3+)

- [ ] Recomendaciones personalizadas (ML b√°sico)
- [ ] Integraci√≥n con Spotify (artistas relacionados)
- [ ] Compartir eventos en redes sociales
- [ ] API p√∫blica para terceros
- [ ] Migraci√≥n de scraping a Go (si >20 fuentes)

---

## Adenda: Mejoras Pendientes de Evaluaci√≥n

> **Prop√≥sito**: Mejoras identificadas durante an√°lisis de documentaci√≥n (Noviembre 2025) que requieren decisi√≥n de producto antes de implementar.

### üî¥ Alta Prioridad

**1. Restricciones T√©cnicas No Documentadas**

**Problema**: No hay l√≠mites expl√≠citos para capacidad SQLite, rate limits de APIs, pol√≠tica de retenci√≥n de datos, ni usuarios concurrentes esperados.

**Impacto**: Sin l√≠mites claros, dif√≠cil estimar escalabilidad y costos operacionales.

**Acci√≥n Sugerida**: Agregar secci√≥n "Technical Constraints" despu√©s de "Core Features" (l√≠nea ~40) con:
- L√≠mite de eventos en SQLite (ej: 50K eventos antes de migrar a PostgreSQL)
- Rate limits por fuente (Ticketmaster: 5000/d√≠a, Eventbrite: 1000/d√≠a)
- Retenci√≥n de datos (ej: purgar eventos >90 d√≠as pasados)
- Capacidad concurrente (ej: 100 usuarios simult√°neos en MVP)

**Referencia**: L√≠nea 40

---

**2. Algoritmo de Deduplicaci√≥n Vago (US3.3)**

**Problema**: Acceptance criteria dicen ">85% similar" sin especificar:
- Algoritmo exacto (¬øLevenshtein distance? ¬øJaro-Winkler? ¬øFuzzy string matching?)
- L√≥gica AND/OR: ¬ølas 3 condiciones (t√≠tulo + fecha + venue) deben cumplirse TODAS o ALGUNA?
- Qu√© hacer con confianza 70-85% (¬øignorar? ¬ørevisi√≥n manual? ¬ømarcar como sospechoso?)

**Impacto**: Implementaci√≥n ambigua puede causar falsos positivos/negativos en deduplicaci√≥n.

**Acci√≥n Sugerida**: En US3.3 acceptance criteria, especificar:
```
- Usar Jaro-Winkler similarity para t√≠tulos (threshold: 0.85)
- Condiciones: (similarity_title > 0.85) AND (date_diff < 24h) AND (venue_match OR venue_similar > 0.7)
- Si 0.70 < similarity < 0.85: marcar como "posible duplicado" para revisi√≥n manual (post-MVP)
```

**Referencia**: L√≠neas 284-301

---

**3. Estrategia de Reintentos Incompleta (US3.1)**

**Problema**: Se menciona "retries con backoff" pero faltan detalles cr√≠ticos:
- N√∫mero m√°ximo de reintentos antes de marcar fuente como fallida
- Qu√© hacer con fallos parciales (ej: scrape√≥ 500 eventos, luego timeout en evento 501)
- Procedimiento de recovery cuando TODAS las fuentes fallan

**Impacto**: Sin estrategia clara, scraping puede ser fr√°gil y datos inconsistentes.

**Acci√≥n Sugerida**: Agregar a US3.1 acceptance criteria:
```
- Retry strategy: 3 intentos con exponential backoff (2s, 4s, 8s)
- Fallos parciales: guardar eventos exitosos, loggear error con √∫ltimo √≠ndice procesado
- Si todas las fuentes fallan: enviar alerta, mantener eventos anteriores, reintentar en pr√≥ximo cron
- Timeout por fuente: 30 segundos
```

**Referencia**: L√≠neas 240-260

---

### üü° Media Prioridad

**4. Conflicto de Prioridad: US3.0 vs Automatizaci√≥n**

**Problema**: US3.0 (scraping manual) es CR√çTICO, pero roadmap muestra automatizaci√≥n (GitHub Actions cron) en Fase 6 (D√≠a 9), DESPU√âS de implementar UI (Fase 5). Esto crea confusi√≥n: ¬øc√≥mo buscan usuarios eventos si no hay scraping autom√°tico?

**Impacto**: Dependencia no clara puede causar retrasos o expectativas incorrectas.

**Acci√≥n Sugerida**: Clarificar en Roadmap Fase 2-4 que:
```
"Hasta Fase 6, scraping es manual v√≠a endpoint /api/admin/scrape.
Ejecutar manualmente 1 vez antes de cada demo/test de UI."
```
O alternativamente: mover implementaci√≥n de cron a Fase 3 (antes de UI).

**Referencia**: L√≠neas 186-238, 413-428

---

**5. US1.3 (Ordenamiento) Sin Acceptance Criteria**

**Problema**: US1.3 "Ordenamiento de resultados" aparece en Epic 1 pero no tiene user story dedicada con acceptance criteria. Falta especificar:
- Orden por defecto (¬øfecha ascendente? ¬ørelevancia?)
- Opciones de ordenamiento disponibles (fecha, popularidad, precio)
- Si ordenamiento persiste en URL query params

**Impacto**: Implementaci√≥n inconsistente o incompleta de funcionalidad b√°sica.

**Acci√≥n Sugerida**:
- Opci√≥n A: Agregar US1.3 completa despu√©s de US1.2 (l√≠nea ~180) con AC detallados
- Opci√≥n B: Mover a "Post-MVP" si no es cr√≠tico para lanzamiento

**Referencia**: L√≠nea 52

---

**6. L√≥gica de Persistencia de Preferencias Ambigua (US3.4/3.5)**

**Problema**: Cuando preferencias cambian y activan `needsRescraping=true`, no est√° claro:
- ¬øEventos existentes se re-eval√∫an contra nuevas reglas y se purgan si ya no cumplen?
- Nuevo scraping: ¬øREEMPLAZA todos los eventos o AGREGA/MERGE con existentes?
- ¬øQu√© pasa si usuario ampl√≠a scope (m√°s g√©neros) y luego lo reduce de nuevo?

**Impacto**: Comportamiento inesperado en datos, posible confusi√≥n de usuarios.

**Acci√≥n Sugerida**: En US3.5 acceptance criteria, especificar estrategia de migraci√≥n:
```
Opci√≥n A (REPLACE): Purgar todos eventos, rescrape completo
Opci√≥n B (APPEND): Mantener eventos existentes, agregar nuevos que cumplan nuevas reglas
Opci√≥n C (MERGE): Re-evaluar existentes, purgar los que no cumplen, agregar nuevos
```
Recomendar Opci√≥n C para mejor UX.

**Referencia**: L√≠neas 304-357

---

### üü¢ Baja Prioridad

**7. Edge Cases Faltantes en B√∫squeda (US1.1)**

**Problema**: Buena cobertura de AC pero faltan casos edge:
- Caracteres especiales en nombres de bandas (ej: "AC/DC", "C#", "M√∂tley Cr√ºe")
- Stopwords en b√∫squeda ("The Rolling Stones" vs "Rolling Stones")
- L√≠mite m√°ximo de caracteres en query (prevenci√≥n DoS)

**Impacto**: B√∫squedas pueden fallar o ser vulnerables a abuso.

**Acci√≥n Sugerida**: Agregar 2-3 AC a US1.1:
```
- B√∫squeda normaliza caracteres especiales (/ ‚Üí espacio, acentos removidos)
- Stopwords ignorados en matching ("the", "a", "an", "los", "las")
- Max length de b√∫squeda: 100 caracteres (retornar 400 Bad Request si excede)
```

**Referencia**: L√≠neas 118-137

---

## Notas de Implementaci√≥n

- **Prioridad de revisi√≥n**: Abordar items üî¥ Alta antes de Fase 2 de implementaci√≥n
- **Items üü° Media**: Resolver antes de Fase 4 (UI)
- **Items üü¢ Baja**: Evaluar durante code review o post-MVP
- **Actualizar esta adenda**: Marcar items resueltos y agregar fecha de resoluci√≥n

---

**√öltima actualizaci√≥n**: Noviembre 2025
