# Product Documentation - EnVivo

## Tabla de Contenidos

1. [Features del MVP](#features-del-mvp)
2. [√âpicas](#√©picas)
3. [Definici√≥n de Terminado (General)](#definici√≥n-de-terminado-general)
4. [User Stories](#user-stories)
5. [Roadmap de Implementaci√≥n](#roadmap-de-implementaci√≥n)
6. [M√©tricas de √âxito](#m√©tricas-de-√©xito)
7. [Checklist Pre-Launch](#checklist-pre-launch)

---

## Features del MVP

### ‚úÖ Core Features (Must-Have)

| Feature | Descripci√≥n | Prioridad | Estado |
|---------|-------------|-----------|--------|
| **B√∫squeda por texto** | Buscar eventos por t√≠tulo, artista o venue | üî¥ CR√çTICO | ‚è≥ Fase 3 |
| **Filtros avanzados** | Filtrar por ciudad, fecha, categor√≠a | üî¥ CR√çTICO | ‚è≥ Fase 3 |
| **Detalle de evento** | Ver informaci√≥n completa del evento | üî¥ CR√çTICO | ‚è≥ Fase 5 |
| **Scraping autom√°tico** | Actualizaci√≥n diaria de eventos | üî¥ CR√çTICO | ‚è≥ Fase 6 |
| **Integraci√≥n Ticketmaster** | API de Ticketmaster como fuente principal | üî¥ CR√çTICO | ‚úÖ Fase 1 |
| **Scrapers locales** | M√≠nimo 2 sitios locales scrapeados | üü° IMPORTANTE | ‚è≥ Fase 5+ |
| **Validaci√≥n de datos** | Reglas de negocio para calidad de datos | üü° IMPORTANTE | üöß Fase 2 |
| **Deduplicaci√≥n** | Detectar eventos duplicados autom√°ticamente | üü° IMPORTANTE | üöß Fase 2 |

### üö´ NO Incluir en MVP (Post-MVP)

| Feature | Por qu√© NO en MVP | Cu√°ndo Agregar |
|---------|-------------------|----------------|
| Cuentas de usuario | No es necesario para b√∫squeda b√°sica | Fase 2 (Mes 2) |
| Favoritos/guardados | Requiere autenticaci√≥n | Fase 2 |
| Notificaciones | Requiere usuarios + infraestructura | Fase 3 |
| Recomendaciones personalizadas | Requiere ML + historial | Fase 3 |
| Integraci√≥n Spotify | Nice-to-have, no core | Fase 2-3 |
| Compra de entradas directa | Complejidad legal/financiera | Nunca (links externos OK) |

---

## √âpicas

### Epic 1: B√∫squeda de Eventos

**Objetivo**: Los usuarios pueden buscar y filtrar eventos musicales f√°cilmente.

**User Stories**:
- US1.1: B√∫squeda por texto
- US1.2: Filtros avanzados (ciudad, fecha, categor√≠a)
- US1.3: Ordenamiento de resultados

**Criterios de √âxito**:
- B√∫squeda responde en <500ms (p95)
- Filtros se pueden combinar
- Resultados relevantes (FTS5)

---

### Epic 2: Visualizaci√≥n de Eventos

**Objetivo**: Los usuarios pueden ver informaci√≥n detallada de eventos.

**User Stories**:
- US2.1: Ver detalle completo de evento
- US2.2: Ver ubicaci√≥n en mapa (opcional MVP)
- US2.3: Link a compra de entradas

**Criterios de √âxito**:
- Toda la informaci√≥n visible (t√≠tulo, fecha, venue, precio)
- Im√°genes optimizadas (Next.js Image)
- Links externos funcionan

---

### Epic 3: Scraping y Gesti√≥n de Datos

**Objetivo**: El sistema mantiene datos actualizados autom√°ticamente.

**User Stories**:
- US3.0a: Scraping manual b√°sico (Fase 1 - Implementado)
- US3.0b: Scraping manual completo con business rules (Fase 2)
- US3.1: Scraping autom√°tico diario
- US3.2: Validaci√≥n de datos
- US3.3: Deduplicaci√≥n de eventos
- US3.4: Configuraci√≥n de preferencias globales (Post-MVP Fase 1.5)
- US3.5: Re-scraping manual con preferencias actualizadas (Post-MVP Fase 1.5)

**Criterios de √âxito**:
- BD se puede poblar desde cero con scraping manual
- Scraping >90% success rate
- No eventos duplicados en BD
- Logs claros de cada ejecuci√≥n
- Eventos rechazados por preferencias quedan registrados con raz√≥n
- Preferencias se pueden configurar v√≠a UI admin (Post-MVP)

**Nota**: Scraping manual b√°sico (US3.0a - `POST /api/admin/scraper/sync`) est√° **IMPLEMENTADO en Fase 1** - permite poblar BD inicial. Business rules y deduplicaci√≥n se agregan en Fase 2 (US3.0b).

---

## Definici√≥n de Terminado (General)

Aplica a todas las historias de usuario del MVP.

- [ ] Tests relevantes pasan (unitarios e integraci√≥n seg√∫n corresponda)
- [ ] Tipado TypeScript sin errores (`npm run type-check`)
- [ ] Linter y formato sin issues (`npm run lint` y Prettier)
- [ ] Manejo de errores y estados de carga implementados
- [ ] Logs m√≠nimos √∫tiles sin datos sensibles
- [ ] UI responsive b√°sica y accesible (navegable con teclado, labels)
- [ ] Performance razonable para el caso (sin bloqueos visibles en UI)
- [ ] Documentaci√≥n t√©cnica m√≠nima en el c√≥digo donde sea necesario

---

## User Stories

### US1.1: B√∫squeda por Texto

**Como** usuario
**Quiero** buscar eventos por t√≠tulo o artista
**Para** encontrar shows que me interesan

**Criterios de Aceptaci√≥n**:
- [ ] Puedo escribir texto en la barra de b√∫squeda
- [ ] Los resultados se filtran al presionar "Buscar" o Enter
- [ ] Se muestran al menos: t√≠tulo, fecha, venue, imagen
- [ ] Si no hay resultados, se muestra mensaje claro
- [ ] La b√∫squeda funciona con acentos o sin ellos (ej: "Metallica" = "Met√°llica")
- [ ] B√∫squeda case-insensitive
- [ ] Si la consulta tiene menos de 2 caracteres, no se ejecuta b√∫squeda y se muestra sugerencia para ampliar el t√©rmino
- [ ] Resultados paginados o con "cargar m√°s" y se muestra el conteo total de resultados

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US1.2: Filtros Avanzados

**Como** usuario
**Quiero** filtrar eventos por ciudad, fecha y categor√≠a
**Para** encontrar eventos espec√≠ficos de mi inter√©s

**Criterios de Aceptaci√≥n**:
- [ ] Puedo seleccionar ciudad de una lista (dropdown)
- [ ] Puedo seleccionar rango de fechas con date picker
- [ ] Puedo filtrar por categor√≠a (Concierto, Festival, Teatro, Stand-up)
- [ ] Los filtros se pueden combinar (ej: Buenos Aires + Conciertos + Pr√≥xima semana)
- [ ] Los filtros se pueden limpiar con un bot√≥n "Limpiar filtros"
- [ ] Filtros persisten en URL (compartibles via link)
 - [ ] Al cambiar filtros, la vista vuelve al inicio de la lista de resultados
 - [ ] Valores inv√°lidos de filtros recibidos por URL se ignoran y se normalizan a valores por defecto

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US2.1: Ver Detalle de Evento

**Como** usuario
**Quiero** ver informaci√≥n completa de un evento
**Para** decidir si quiero asistir

**Criterios de Aceptaci√≥n**:
- [ ] Se muestra imagen del evento (o placeholder si no hay)
- [ ] Se muestra t√≠tulo, fecha, hora, venue
- [ ] Se muestra descripci√≥n completa (si est√° disponible)
- [ ] Se muestra precio (si est√° disponible)
- [ ] Hay bot√≥n "Comprar entradas" que abre link externo en nueva pesta√±a
- [ ] Se muestra mapa con ubicaci√≥n del venue (opcional para MVP)
- [ ] Se muestran artistas participantes (si hay)
 - [ ] Si el evento no existe, se muestra p√°gina 404 con mensaje claro
 - [ ] Las im√°genes muestran skeleton de carga y fallback ante error
 - [ ] Existe un enlace "Volver a resultados" que preserva query y filtros previos

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US3.0a: Scraping Manual B√°sico (Fase 1 - Implementado)

**Como** administrador del sistema
**Quiero** ejecutar scraping manual de Ticketmaster para poblar la BD
**Para** tener datos iniciales y poder probar la UI

**Contexto**: Al iniciar el proyecto, la BD est√° vac√≠a. Este endpoint permite llenarla manualmente con datos de Ticketmaster.

**Criterios de Aceptaci√≥n**:
- [x] Endpoint `POST /api/admin/scraper/sync` disponible
- [x] Requiere autenticaci√≥n con header `x-api-key` (m√≠nimo 32 caracteres)
- [x] Acepta par√°metros opcionales en body JSON:
  - `country`: string (default: 'AR')
  - `city`: string (opcional)
- [x] Ejecuta scraping de Ticketmaster API
- [x] Guarda todos los eventos en BD (sin filtrado por business rules en Fase 1)
- [x] Retorna resumen JSON: source, eventsScraped, eventsSaved, timestamp
- [x] Manejo de errores con try/catch y respuesta 500 con mensaje de error

**Definici√≥n de Terminado**: ‚úÖ Completado en Fase 1

**Prioridad**: üî¥ CR√çTICO

**Ejemplo de uso**:
```bash
# Scraping b√°sico (default: Argentina)
curl -X POST http://localhost:3000/api/admin/scraper/sync \
  -H "x-api-key: your-admin-key-min-32-chars"

# Con par√°metros opcionales
curl -X POST http://localhost:3000/api/admin/scraper/sync \
  -H "x-api-key: your-admin-key-min-32-chars" \
  -H "Content-Type: application/json" \
  -d '{"country": "AR", "city": "Buenos Aires"}'
```

**Respuesta actual (Fase 1)**:
```json
{
  "success": true,
  "source": "ticketmaster",
  "eventsScraped": 150,
  "eventsSaved": 150,
  "timestamp": "2025-11-08T10:30:00.000Z"
}
```

---

### US3.0b: Scraping Manual Completo con Business Rules (Fase 2 - Planificado)

**Como** administrador del sistema
**Quiero** ejecutar scraping con validaci√≥n, deduplicaci√≥n y preferencias globales
**Para** tener solo eventos relevantes y de calidad en la BD

**Contexto**: Mejora sobre US3.0a agregando business rules, m√∫ltiples fuentes, deduplicaci√≥n y gesti√≥n de preferencias.

**Criterios de Aceptaci√≥n**:
- [ ] Carga preferencias por defecto si no existen (lazy initialization):
  - allowedCountries: `['AR']`
  - allowedCities: `['Buenos Aires', 'Ciudad de Buenos Aires', 'CABA']`
  - allowedCategories: `['Music', 'Concert', 'Festival']`
  - allowedVenueSizes: `['small', 'medium', 'large']`
- [ ] Ejecuta scraping de todas las fuentes configuradas en paralelo (Ticketmaster + futuras fuentes)
- [ ] Aplica validaci√≥n de business rules antes de guardar:
  - Rechaza eventos sin t√≠tulo, fecha o venue
  - Rechaza fechas pasadas >1 d√≠a
  - Rechaza pa√≠ses/ciudades fuera de allowedCountries/allowedCities
  - Valida t√≠tulos (m√≠nimo 3 caracteres)
- [ ] Deduplica eventos antes de guardar (fuzzy matching >85% similaridad)
- [ ] Retorna resumen JSON: total scrapeado, aceptados, rechazados, razones de rechazo, duraci√≥n
- [ ] Marca `needsRescraping=false` al finalizar exitosamente
- [ ] Rate limiting: m√°ximo 10 requests cada 10 segundos
- [ ] Timeout global: 5 minutos
- [ ] Logs estructurados con Pino (redactando API keys)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE (Fase 2)

**Respuesta esperada (Fase 2)**:
```json
{
  "success": true,
  "summary": {
    "totalScraped": 500,
    "accepted": 350,
    "rejected": 150,
    "durationMs": 4200
  },
  "rejectionReasons": {
    "COUNTRY_NOT_ALLOWED": 80,
    "INVALID_DATE_PAST": 70
  },
  "timestamp": "2025-11-08T10:30:00.000Z"
}
```

---

### US3.1: Scraping Autom√°tico Diario

**Como** administrador del sistema
**Quiero** que los datos se actualicen autom√°ticamente cada d√≠a
**Para** tener eventos siempre actualizados sin intervenci√≥n manual

**Criterios de Aceptaci√≥n**:
- [ ] El scraping se ejecuta diariamente a las 2 AM UTC
- [ ] Se scrapean m√≠nimo 3 fuentes (Ticketmaster + 2 locales)
- [ ] Los eventos duplicados no se guardan (fuzzy matching)
- [ ] Los eventos pasados se mantienen en BD (hist√≥rico) pero no se muestran
- [ ] Se env√≠a notificaci√≥n (log visible) si el scraping falla
- [ ] Se pueden ver logs de √∫ltima ejecuci√≥n en `/api/scraper/status`
 - [ ] Si una fuente falla, el estado expone fuente, timestamp y motivo del fallo
 - [ ] Retries con backoff quedan registrados por fuente con contador visible en el estado

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üî¥ CR√çTICO

---

### US3.2: Validaci√≥n de Datos

**Como** sistema
**Quiero** validar todos los eventos antes de guardarlos
**Para** asegurar calidad de datos en la aplicaci√≥n

**Criterios de Aceptaci√≥n**:
- [ ] Eventos sin t√≠tulo se rechazan
- [ ] Eventos sin fecha se rechazan
- [ ] Eventos sin venue se rechazan
- [ ] Fechas pasadas >1 d√≠as se rechazan
- [ ] Pa√≠ses fuera de la lista permitida se rechazan
- [ ] T√≠tulos demasiado cortos (<3 caracteres) se rechazan
- [ ] Se loggean eventos rechazados con raz√≥n clara
- [ ] La raz√≥n de rechazo se persiste con un c√≥digo estandarizado (p.ej., MISSING_DATE, OUT_OF_SCOPE_COUNTRY)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE

---

### US3.3: Deduplicaci√≥n de Eventos

**Como** usuario
**Quiero** rechazar eventos duplicados de diferentes fuentes
**Para** no mostrar el mismo evento m√∫ltiples veces

**Criterios de Aceptaci√≥n**:
- [ ] Eventos con t√≠tulos >85% similares se consideran duplicados
- [ ] Eventos en la misma fecha ¬±24h se consideran duplicados
- [ ] Eventos en el mismo venue se consideran duplicados
- [ ] Se prefiere la fuente m√°s confiable (ej: Ticketmaster > scraper local)
- [ ] Se mergean campos si una fuente tiene m√°s informaci√≥n
 - [ ] No hay duplicados visibles en la UI tras el proceso de deduplicaci√≥n

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE

---

### US3.4: Configuraci√≥n de Preferencias Globales (UI Admin)

**Como** administrador del sistema
**Quiero** configurar preferencias globales de scraping
**Para** obtener solo eventos relevantes y optimizar uso de recursos

**Criterios de Aceptaci√≥n**:
- [ ] Puedo acceder a p√°gina `/admin/preferences` con formulario de configuraci√≥n
- [ ] Puedo configurar pa√≠ses permitidos (multi-select con c√≥digos ISO)
- [ ] Puedo configurar ciudades espec√≠ficas (opcional, lista editable)
- [ ] Puedo seleccionar g√©neros musicales de inter√©s (multi-select)
- [ ] Puedo seleccionar g√©neros bloqueados (lista negra opcional)
- [ ] Puedo elegir categor√≠as de eventos permitidas (Concierto, Festival, Teatro, etc.)
- [ ] Puedo filtrar por tama√±o de venue (peque√±o <500, mediano 500-2000, grande >2000)
- [ ] Los umbrales de capacidad de venue son configurables
- [ ] Las preferencias se guardan en base de datos (tabla GlobalPreferences)
- [ ] Cambiar preferencias marca autom√°ticamente necesidad de re-scraping
- [ ] Hay bot√≥n "Guardar" (solo guarda) y "Guardar y Re-scrapear Ahora" (ejecuta scraping inmediato)
- [ ] La p√°gina muestra √∫ltima actualizaci√≥n y conteo de eventos actuales en BD
- [ ] Hay validaci√≥n: al menos 1 pa√≠s debe estar seleccionado
- [ ] Se muestra modal de confirmaci√≥n antes de ejecutar re-scraping
- [ ] Durante re-scraping se muestra progreso o spinner
- [ ] Al completar, se muestra resumen de eventos scrapeados/aceptados/rechazados

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE (Post-MVP Fase 1.5)

---

### US3.5: Re-scraping Manual con Preferencias Actualizadas

**Como** administrador
**Quiero** ejecutar scraping manual despu√©s de cambiar preferencias
**Para** actualizar la BD con los nuevos filtros

**Contexto**: Cuando se actualizan preferencias globales (ej: agregar m√°s pa√≠ses), se marca `needsRescraping=true`. Este flujo aplica los nuevos filtros.

**Criterios de Aceptaci√≥n**:
- [ ] Endpoint `POST /api/admin/scraper/sync?applyNewPreferences=true` disponible
- [ ] Invalida cach√© de preferencias antes de scrapear
- [ ] Lee nuevas preferencias de BD
- [ ] Ejecuta scraping aplicando nuevos filtros
- [ ] Solo guarda eventos que cumplen nuevas preferencias
- [ ] Marca `needsRescraping=false` al finalizar exitosamente
- [ ] Retorna resumen con eventos aceptados/rechazados por las nuevas reglas
- [ ] Si scraping falla, no marca como completado (permite retry)

**Definici√≥n de Terminado**: Aplica DoD general.

**Prioridad**: üü° IMPORTANTE (Post-MVP Fase 1.5)

**Nota**: El endpoint base (`POST /api/admin/scraper/sync`) ya existe desde US3.0. Esta US solo agrega el par√°metro `applyNewPreferences`.

---

## Roadmap de Implementaci√≥n

### Enfoque: Vertical Slices (Features End-to-End)

En lugar de implementar horizontalmente por capas (toda la capa de datos, luego l√≥gica, luego UI), este roadmap sigue **vertical slices** - implementar features completas end-to-end que proveen valor inmediato.

**Ventajas**:
- ‚úÖ Valor inmediato: algo funcional en 1-2 d√≠as (no 10 d√≠as)
- ‚úÖ Feedback r√°pido: UI con datos reales desde la primera fase
- ‚úÖ Menos overhead: no implementar infraestructura compleja hasta que sea necesaria
- ‚úÖ Deployable: cada fase puede ir a producci√≥n
- ‚úÖ Testeable: cada slice incluye sus tests

**Git Workflow**: Commit y push al trunk (`main`) despu√©s de completar cada fase.

---

### Fase 0: Setup & Configuraci√≥n (4-6 horas)

**Objetivo**: Proyecto corriendo con infraestructura b√°sica.

**Tareas**:
1. Inicializar Next.js 14 con TypeScript, Tailwind, App Router
2. Instalar dependencias core: Prisma, Zod, Vitest
3. Setup Prisma + SQLite
4. Configurar variables de entorno (.env.example ‚Üí .env.local)
5. Crear estructura de carpetas seg√∫n Clean Architecture
6. Configurar ESLint + Prettier
7. Configurar Vitest para tests unitarios

**Entregable**:
- ‚úÖ `npm run dev` funciona
- ‚úÖ Estructura de carpetas creada
- ‚úÖ Prisma configurado
- ‚úÖ ESLint + Prettier funcionando

**Git**: `git commit -m "feat: initial setup" && git push`

---

### Fase 1: Primer Vertical Slice - "Mostrar Eventos de Ticketmaster" (1-2 d√≠as)

**Objetivo**: Desde scraping hasta UI, un flujo completo funcionando.

**Orden de implementaci√≥n**:

1. **Schema de BD m√≠nimo**
   - Solo `Event` model (sin artistas, sin venues separados por ahora)
   - Campos: id, title, date, venue, city, country, imageUrl, ticketUrl, source

2. **Interfaces del Domain**
   - `IDataSource` (interface m√≠nima)
   - `IEventRepository`

3. **TicketmasterSource + Mapper** (capa Data)
   - `TicketmasterSource` implementa `IDataSource`
   - `TicketmasterMapper` mapea de API a entidad `Event`

4. **Repository con Prisma**
   - `PrismaEventRepository` implementa `IEventRepository`
   - M√©todos: `findAll()`, `upsertMany()`

5. **API Route para scraping manual**
   - `POST /api/admin/scraper/sync`
   - Validar API key
   - Ejecutar TicketmasterSource.fetch()
   - Guardar en BD con repository
   - Retornar resumen JSON

6. **UI b√°sica - Lista de eventos**
   - Server Component en `app/page.tsx`
   - Componente `EventCard` simple
   - Mostrar eventos ordenados por fecha

**Tests m√≠nimos**:
- Unit test de `TicketmasterMapper`
- Integration test de `PrismaEventRepository`

**Entregable**:
üéâ **Puedes ejecutar scraping manual y ver eventos en la UI**

**Git**: `git commit -m "feat: first vertical slice - Ticketmaster to UI" && git push`

---

### Fase 2: Business Rules + Deduplicaci√≥n (1 d√≠a)

**Objetivo**: Validaci√≥n centralizada y sin duplicados.

**Tareas**:
1. Crear `EventBusinessRules` en capa Domain
2. Implementar validaci√≥n b√°sica (fechas, campos requeridos, ubicaci√≥n)
3. Implementar deduplicaci√≥n con fuzzy matching (`string-similarity`)
4. Crear archivo de configuraci√≥n `config/business-rules.json`
5. Integrar business rules en flujo de scraping (entre mapper y repository)
6. Tests unitarios de business rules (>80% coverage)
7. Tests de deduplicaci√≥n con casos edge

**Entregable**:
- ‚úÖ Eventos inv√°lidos se rechazan con logs claros
- ‚úÖ No hay duplicados en BD

**Git**: `git commit -m "feat: business rules and deduplication" && git push`

---

### Fase 3: B√∫squeda + Filtros (1-2 d√≠as)

**Objetivo**: US1.1 (B√∫squeda por texto) y US1.2 (Filtros) completos.

**Tareas**:
1. Agregar SQLite FTS5 a schema (`@@fulltext([title, description])`)
2. Crear `SearchService` en capa Domain
3. Implementar API Route `GET /api/eventos?q=...&city=...&date=...`
4. Validaci√≥n de query params con Zod
5. Implementar `SearchBar` component con debounce
6. Implementar `EventFilters` component (ciudad, fecha, categor√≠a)
7. Actualizar `EventList` para aceptar filtros
8. Persistir filtros en URL query params
9. Tests de SearchService
10. Tests de integraci√≥n de API route

**Entregable**:
- ‚úÖ Buscador funcional por texto
- ‚úÖ Filtros combinables (ciudad + fecha + categor√≠a)
- ‚úÖ Resultados en <500ms

**Git**: `git commit -m "feat: search and filters" && git push`

---

### Fase 4: Orchestrator + Scraping Paralelo (1 d√≠a)

**Objetivo**: Preparar arquitectura para m√∫ltiples fuentes.

**Tareas**:
1. Crear `DataSourceOrchestrator` con `Promise.allSettled()`
2. Implementar l√≠mite de concurrencia con `p-limit`
3. Implementar retry logic con `p-retry`
4. Agregar timeout handling por fuente
5. Crear archivo de configuraci√≥n `config/scrapers.json`
6. Refactorizar scraping endpoint para usar orchestrator
7. Tests unitarios de orchestrator (con mocks de data sources)

**Nota**: Por ahora solo hay 1 fuente (Ticketmaster), pero arquitectura lista para escalar.

**Entregable**:
- ‚úÖ Orchestrator funciona con 1 fuente
- ‚úÖ Listo para agregar m√°s fuentes f√°cilmente

**Git**: `git commit -m "feat: data source orchestrator with async scraping" && git push`

---

### Fase 5: Segunda Fuente + Detalle de Evento (1 d√≠a)

**Objetivo**: Validar que orchestrator funciona con m√∫ltiples fuentes + US2.1 (Detalle).

**Tareas**:
1. Implementar segunda fuente (Eventbrite API o scraper local simple)
2. Crear mapper correspondiente
3. Registrar en orchestrator
4. Verificar deduplicaci√≥n entre fuentes funciona
5. Crear p√°gina de detalle `/eventos/[id]/page.tsx`
6. Crear componente `EventDetail`
7. Agregar link "Volver a resultados" que preserva query params
8. Tests de nueva fuente
9. Tests E2E b√°sicos (navegar home ‚Üí detalle)

**Entregable**:
- ‚úÖ Scraping de 2+ fuentes en paralelo
- ‚úÖ P√°gina de detalle completa

**Git**: `git commit -m "feat: second data source and event detail page" && git push`

---

### Fase 6: Scraping Autom√°tico + Deploy (1 d√≠a)

**Objetivo**: Automatizaci√≥n y producci√≥n.

**Tareas**:
1. Crear GitHub Action con cron diario (2 AM UTC)
2. Implementar logging estructurado con Pino
3. Configurar redacci√≥n de secretos en logs
4. Crear `GET /api/scraper/status` endpoint
5. Deploy a Vercel
6. Configurar variables de entorno en Vercel
7. Configurar variable `ADMIN_API_KEY` en GitHub Secrets
8. Verificar scraping autom√°tico ejecuta correctamente
9. Tests de integraci√≥n del cron job (local)

**Entregable**:
- ‚úÖ Scraping autom√°tico diario funcionando
- ‚úÖ App en producci√≥n en Vercel
- ‚úÖ Logs estructurados visibles

**Git**: `git commit -m "feat: automated scraping and production deployment" && git push`

---

### Fase 7: Pulido + Testing E2E (1 d√≠a)

**Objetivo**: Calidad y lanzamiento del MVP.

**Tareas**:
1. Setup Playwright para E2E
2. Tests E2E de flujos cr√≠ticos:
   - B√∫squeda por texto
   - Aplicar filtros
   - Ver detalle de evento
   - Scraping manual (admin)
3. Implementar Error boundaries
4. Mejorar loading states (skeletons)
5. Responsive design (mobile + tablet)
6. Optimizaci√≥n de im√°genes (Next.js Image)
7. Performance audit con Lighthouse (>90)
8. Security audit (`npm audit`)
9. Verificar coverage de tests (>80% domain, >60% total)

**Entregable**:
- ‚úÖ MVP completo y testeado
- ‚úÖ Lighthouse score >90
- ‚úÖ Tests E2E pasan
- ‚úÖ Listo para usuarios reales

**Git**: `git commit -m "feat: E2E tests and production polish" && git push`

---

## M√©tricas de √âxito

### Objetivos del MVP

| M√©trica | Objetivo | C√≥mo Medirlo |
|---------|----------|--------------|
| **Performance** | B√∫squeda <500ms (p95) | Vercel Analytics |
| **Disponibilidad** | >99% uptime | Vercel Monitoring |
| **Datos** | >500 eventos activos | Query a BD: `SELECT COUNT(*) FROM Event WHERE date > NOW()` |
| **Scraping Success Rate** | >90% de fuentes exitosas | Logs del orchestrator |
| **Cobertura de Tests** | >80% dominio, >60% total | Vitest coverage report |
| **Errores en Producci√≥n** | <5 errores/d√≠a | Sentry o Vercel logs |
| **Lighthouse Score** | >90 Performance | Lighthouse CI |

### KPIs de Negocio (Post-MVP)

| KPI | Objetivo (Mes 1) | C√≥mo Medirlo |
|-----|------------------|--------------|
| B√∫squedas/d√≠a | 50+ | Log de requests a `/api/eventos` |
| Eventos mostrados/d√≠a | 200+ | Log de visualizaciones |

---

## Checklist Pre-Launch

### Funcionalidad

- [ ] B√∫squeda por texto funciona correctamente
- [ ] Filtros (ciudad, fecha, categor√≠a) funcionan y se pueden combinar
- [ ] Detalle de evento muestra toda la informaci√≥n
- [ ] Links a compra de entradas se abren en nueva pesta√±a
- [ ] Scraping diario configurado y funcionando
- [ ] No hay eventos duplicados visibles

### Calidad

- [ ] Tests unitarios >80% cobertura (capa de dominio)
- [ ] Tests E2E para flujos cr√≠ticos (b√∫squeda, detalle) pasan
- [ ] No hay errores de TypeScript (`npm run type-check`)
- [ ] Linter pasa sin warnings (`npm run lint`)
- [ ] C√≥digo formateado con Prettier

### Performance

- [ ] Lighthouse score >90 (Performance)
- [ ] B√∫squeda responde en <500ms con 1000+ eventos
- [ ] Im√°genes optimizadas con Next.js Image component
- [ ] Lazy loading de componentes pesados
- [ ] Build de producci√≥n exitoso (`npm run build`)

### Seguridad

**Ver [SECURITY.md](SECURITY.md) para gu√≠a completa de seguridad.**

- [ ] Validaci√≥n Zod en todos los inputs de API
- [ ] Rate limiting implementado en endpoints p√∫blicos
- [ ] Headers de seguridad configurados (CSP, HSTS, X-Frame-Options)
- [ ] No hay secretos hardcoded en c√≥digo
- [ ] `.env` en `.gitignore`
- [ ] `npm audit` sin vulnerabilidades cr√≠ticas o altas
- [ ] Sanitizaci√≥n de datos scrapeados (DOMPurify)

### Deploy

- [ ] Variables de entorno configuradas en Vercel
- [ ] GitHub Actions funcionando (tests + deploy)
- [ ] Dominio configurado (opcional, puede ser subdomain de Vercel)
- [ ] Monitoring activo (Vercel logs + Sentry opcional)
- [ ] Scraping diario ejecut√°ndose correctamente
- [ ] Logs accesibles y legibles

### Documentaci√≥n

- [ ] README.md actualizado con instrucciones
- [ ] Variables de entorno documentadas en `.env.example`
- [ ] Arquitectura documentada en `docs/ARCHITECTURE.md`
- [ ] User stories y roadmap en `docs/PRODUCT.md`

---

## Features Post-MVP (Roadmap Futuro)

### Fase 2 (Mes 2)

- [ ] Autenticaci√≥n con NextAuth.js
- [ ] Favoritos/guardados de eventos
- [ ] Notificaciones de nuevos eventos (email)
- [ ] M√°s scrapers locales (objetivo: 10 fuentes)
- [ ] Migraci√≥n a PostgreSQL (si >10K eventos)

### Fase 3 (Mes 3+)

- [ ] Recomendaciones personalizadas (ML b√°sico)
- [ ] Integraci√≥n con Spotify (artistas relacionados)
- [ ] Compartir eventos en redes sociales
- [ ] API p√∫blica para terceros
- [ ] Migraci√≥n de scraping a Go (si >20 fuentes)

---

## Adenda: Mejoras Pendientes de Evaluaci√≥n

> **Prop√≥sito**: Mejoras identificadas durante an√°lisis de documentaci√≥n (Noviembre 2025) que requieren decisi√≥n de producto antes de implementar.

### üî¥ Alta Prioridad

**1. Restricciones T√©cnicas No Documentadas**

**Problema**: No hay l√≠mites expl√≠citos para capacidad SQLite, rate limits de APIs, pol√≠tica de retenci√≥n de datos, ni usuarios concurrentes esperados.

**Impacto**: Sin l√≠mites claros, dif√≠cil estimar escalabilidad y costos operacionales.

**Acci√≥n Sugerida**: Agregar secci√≥n "Technical Constraints" despu√©s de "Core Features" (l√≠nea ~40) con:
- L√≠mite de eventos en SQLite (ej: 50K eventos antes de migrar a PostgreSQL)
- Rate limits por fuente (Ticketmaster: 5000/d√≠a, Eventbrite: 1000/d√≠a)
- Retenci√≥n de datos (ej: purgar eventos >90 d√≠as pasados)
- Capacidad concurrente (ej: 100 usuarios simult√°neos en MVP)

**Referencia**: L√≠nea 40

---

**2. Algoritmo de Deduplicaci√≥n Vago (US3.3)**

**Problema**: Acceptance criteria dicen ">85% similar" sin especificar:
- Algoritmo exacto (¬øLevenshtein distance? ¬øJaro-Winkler? ¬øFuzzy string matching?)
- L√≥gica AND/OR: ¬ølas 3 condiciones (t√≠tulo + fecha + venue) deben cumplirse TODAS o ALGUNA?
- Qu√© hacer con confianza 70-85% (¬øignorar? ¬ørevisi√≥n manual? ¬ømarcar como sospechoso?)

**Impacto**: Implementaci√≥n ambigua puede causar falsos positivos/negativos en deduplicaci√≥n.

**Acci√≥n Sugerida**: En US3.3 acceptance criteria, especificar:
```
- Usar Jaro-Winkler similarity para t√≠tulos (threshold: 0.85)
- Condiciones: (similarity_title > 0.85) AND (date_diff < 24h) AND (venue_match OR venue_similar > 0.7)
- Si 0.70 < similarity < 0.85: marcar como "posible duplicado" para revisi√≥n manual (post-MVP)
```

**Referencia**: L√≠neas 284-301

---

**3. Estrategia de Reintentos Incompleta (US3.1)**

**Problema**: Se menciona "retries con backoff" pero faltan detalles cr√≠ticos:
- N√∫mero m√°ximo de reintentos antes de marcar fuente como fallida
- Qu√© hacer con fallos parciales (ej: scrape√≥ 500 eventos, luego timeout en evento 501)
- Procedimiento de recovery cuando TODAS las fuentes fallan

**Impacto**: Sin estrategia clara, scraping puede ser fr√°gil y datos inconsistentes.

**Acci√≥n Sugerida**: Agregar a US3.1 acceptance criteria:
```
- Retry strategy: 3 intentos con exponential backoff (2s, 4s, 8s)
- Fallos parciales: guardar eventos exitosos, loggear error con √∫ltimo √≠ndice procesado
- Si todas las fuentes fallan: enviar alerta, mantener eventos anteriores, reintentar en pr√≥ximo cron
- Timeout por fuente: 30 segundos
```

**Referencia**: L√≠neas 240-260

---

### üü° Media Prioridad

**4. Conflicto de Prioridad: US3.0 vs Automatizaci√≥n**

**Problema**: US3.0 (scraping manual) es CR√çTICO, pero roadmap muestra automatizaci√≥n (GitHub Actions cron) en Fase 6 (D√≠a 9), DESPU√âS de implementar UI (Fase 5). Esto crea confusi√≥n: ¬øc√≥mo buscan usuarios eventos si no hay scraping autom√°tico?

**Impacto**: Dependencia no clara puede causar retrasos o expectativas incorrectas.

**Acci√≥n Sugerida**: Clarificar en Roadmap Fase 2-4 que:
```
"Hasta Fase 6, scraping es manual v√≠a endpoint /api/admin/scrape.
Ejecutar manualmente 1 vez antes de cada demo/test de UI."
```
O alternativamente: mover implementaci√≥n de cron a Fase 3 (antes de UI).

**Referencia**: L√≠neas 186-238, 413-428

---

**5. US1.3 (Ordenamiento) Sin Acceptance Criteria**

**Problema**: US1.3 "Ordenamiento de resultados" aparece en Epic 1 pero no tiene user story dedicada con acceptance criteria. Falta especificar:
- Orden por defecto (¬øfecha ascendente? ¬ørelevancia?)
- Opciones de ordenamiento disponibles (fecha, popularidad, precio)
- Si ordenamiento persiste en URL query params

**Impacto**: Implementaci√≥n inconsistente o incompleta de funcionalidad b√°sica.

**Acci√≥n Sugerida**:
- Opci√≥n A: Agregar US1.3 completa despu√©s de US1.2 (l√≠nea ~180) con AC detallados
- Opci√≥n B: Mover a "Post-MVP" si no es cr√≠tico para lanzamiento

**Referencia**: L√≠nea 52

---

**6. L√≥gica de Persistencia de Preferencias Ambigua (US3.4/3.5)**

**Problema**: Cuando preferencias cambian y activan `needsRescraping=true`, no est√° claro:
- ¬øEventos existentes se re-eval√∫an contra nuevas reglas y se purgan si ya no cumplen?
- Nuevo scraping: ¬øREEMPLAZA todos los eventos o AGREGA/MERGE con existentes?
- ¬øQu√© pasa si usuario ampl√≠a scope (m√°s g√©neros) y luego lo reduce de nuevo?

**Impacto**: Comportamiento inesperado en datos, posible confusi√≥n de usuarios.

**Acci√≥n Sugerida**: En US3.5 acceptance criteria, especificar estrategia de migraci√≥n:
```
Opci√≥n A (REPLACE): Purgar todos eventos, rescrape completo
Opci√≥n B (APPEND): Mantener eventos existentes, agregar nuevos que cumplan nuevas reglas
Opci√≥n C (MERGE): Re-evaluar existentes, purgar los que no cumplen, agregar nuevos
```
Recomendar Opci√≥n C para mejor UX.

**Referencia**: L√≠neas 304-357

---

### üü¢ Baja Prioridad

**7. Edge Cases Faltantes en B√∫squeda (US1.1)**

**Problema**: Buena cobertura de AC pero faltan casos edge:
- Caracteres especiales en nombres de bandas (ej: "AC/DC", "C#", "M√∂tley Cr√ºe")
- Stopwords en b√∫squeda ("The Rolling Stones" vs "Rolling Stones")
- L√≠mite m√°ximo de caracteres en query (prevenci√≥n DoS)

**Impacto**: B√∫squedas pueden fallar o ser vulnerables a abuso.

**Acci√≥n Sugerida**: Agregar 2-3 AC a US1.1:
```
- B√∫squeda normaliza caracteres especiales (/ ‚Üí espacio, acentos removidos)
- Stopwords ignorados en matching ("the", "a", "an", "los", "las")
- Max length de b√∫squeda: 100 caracteres (retornar 400 Bad Request si excede)
```

**Referencia**: L√≠neas 118-137

---

## Notas de Implementaci√≥n

- **Prioridad de revisi√≥n**: Abordar items üî¥ Alta antes de Fase 2 de implementaci√≥n
- **Items üü° Media**: Resolver antes de Fase 4 (UI)
- **Items üü¢ Baja**: Evaluar durante code review o post-MVP
- **Actualizar esta adenda**: Marcar items resueltos y agregar fecha de resoluci√≥n

---

**√öltima actualizaci√≥n**: Noviembre 2025
